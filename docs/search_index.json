[
["index.html", "Einführung in die Statistik Vorwort", " Einführung in die Statistik Tobias Krueger 2020-10-26 Vorwort Dies ist das Skript für den Kurs ‘Einführung in die Statistik’ am Geographischen Institut der Humboldt-Universität zu Berlin. "],
["einfuehrung.html", "Chapter 1 Einführung 1.1 Statistik im empirischen Forschungsprozess 1.2 Warum Statistik? 1.3 Organisatorisches 1.4 Mathematische Notation und Grundlagen", " Chapter 1 Einführung Das Modul B3 Einführung in die Statistik und das Fach Geographie besteht aus: Dem Seminar Einführung in die Statistik mit Tobias Krüger (regelmäßiges ZOOM-Treffen montags 11:00-12:30 - s. Moodle link) Dem Seminar Einführung in die Geographie mit Christoph Schneider und Henning Nuissl Der PC-Übung Statistische Datenverarbeitung mit Matthias Baumann, Sebastian Schubert, Heidi Kreibich, Abror Gafurov, Hoseung Jung, Friedrich Busch, Kassandra Jensch und Maeve Smyth (ab 27. November 3-stündig freitags 09:00-12:00 - dazu mehr weiter unten) Das vorliegende Skript ist Grundlage des Seminars Einführung in die Statistik und dient der theoretischen Vorbereitung der PC-Übung Statistische Datenverarbeitung. Organisatorisches dazu weiter unten. Am Ende des Semesters haben Sie ein Grundverständnis der beschreibenden und der schließenden Statistik erworben. Sie können folgende Methoden selbständig in der Software R anwenden und deren Ergebnisse interpretieren: - Beschreibung von Stichproben mit Zentralitäts- und Streuungsmaßen - Beschreibung der Korrelation zwischen Merkmalen - Schätzen von Verteilungsparametern anhand von Stichproben - Test auf Unterschiede in Mittelwerten (t-Test) - Test auf Unterschiede in Varianzen (F-Test) - Test auf Unterschiede in Verteilungen (Kolmogorov-Smirnov-Test) - Test auf Unabhängigkeit (Chi-Quadrat-Test) - Modellierung eines linearen Zusammenhangs zwischen Merkmalen (lineare Regression) - Graphisch Methoden wie Histogramm, Boxplot, Streudiagramm und Quantil-Quantil-Plot Zunächst aber ein paar einleitende Worte zur Statistik in der Geographie. 1.1 Statistik im empirischen Forschungsprozess Lesen Sie dazu bitte Kapitel 2.4 von Zimmermann-Janschitz (2014) - s. Moodle link. Gemäß der dort gewählten Kategorisierung befasst sich die Statistik hauptsächlich mit Datenanalyse (Punkt 7), obwohl die angrenzenden Schritte ebenfalls wichtig sind. Auf Auswahl der Untersuchungseinheit (Punkt 4), Datenerhebung (Punkt 5) und Datenaufbereitung (Punkt 6) werden wir in Kapitel 2 näher eingehen. Punkt 8 (Interpretation und Rückschlüsse) wird durchgehend eine Rolle spielen. 1.2 Warum Statistik? Statistik ist Teil des physisch- und humangeographischen Methodenpakets. Da die Erkenntnisse der Geographie in vielen Teilen auf dem empirischen Forschungsprozess basieren ist statistische Analyse unumgänglich als Argumentationsunterstützung und als Beweissicherung. Außerdem dient sie der Bestätigung oder Widerlegung theoretischer Ansätze und der Generierung neuer Informationen aus verfügbaren Daten. In der Praxis dient Statistik häufig als Entscheidungsgrundlage. Lesen Sie bitte Kapitel 2.3 von Zimmermann-Janschitz (2014) für konkrete Anwendungsbeispiele der Statistik in der Geographie. Aufgabe: Auf Moodle unter Woche 1 finden Sie ein kurzes Quiz zu diesem Kapitel. Bitte beantworten Sie die Fragen bis Ende der Woche. Dies werden wir jede Woche tun, als Lernstandskontrolle für Sie und als Überblick für uns über mögliche Verständnisprobleme. Am Ende von Kapitel 2.3 in Zimmermann-Janschitz (2014) finden Sie außerdem eine Erklärung der Teilbereiche der Statistik. Mit der deskriptiven (beschreibenden) Statistik beschäftigen wir uns in den Wochen 3-5. Dazu ist das Lehrbuch von Zimmermann-Janschitz (2014) wichtig. Mit der induktiven (schließenden) Statistik beschäfigen wir uns in den Wochen 8-13. Die Brücke zwischen diesen beiden Teilbereichen - wie es Zimmermann-Janschitz (2014) darstellt - ist die Wahrscheinlichkeitstheorie, mit deren Grundlagen wir uns in den Wochen 6-7 auseinandersetzen. 1.3 Organisatorisches Die Abfolge der Inhalte des Seminars und der PC-Übung finden Sie in Tabelle 1.1. Table 1.1: Inhalte von Einführung in die Statistik und Statistische Datenverarbeitung. Der gelesene Stoff wird am darauffolgenden Montag im Seminar diskutiert. Die PC-Übung beginnt in Woche 4 am 27. November. Woche Lesen Diskutieren (Montagsseminar) PC-Übung (Freitag) 1 Warum Statistik?; Organisatorisches; Mathematische Grundlagen - - 2 Datenerhebung; Grundbegriffe; Skalen Warum Statistik?; Organisatorisches; Mathematische Grundlagen - 3 Deskriptive Statistik 1 Datenerhebung; Grundbegriffe; Skalen - 4 Deskriptive Statistik 2 Deskriptive Statistik 1 Pre-Übung 5 Deskriptive Statistik 3 Deskriptive Statistik 2 Einführung in R 6 Grundlagen der Wahrscheinlichkeitsrechnung Deskriptive Statistik 3 Dateneingabe, Datenformate, Skalen 7 Verteilungen Grundlagen der Wahrscheinlichkeitsrechnung Deskriptive Statistik 8 Schätzen von Verteilungsparametern Verteilungen Korrelation 9 Statistische Tests 1 Schätzen von Verteilungsparametern Schätzen von Verteilungsparametern 1 “per Hand” in R 10 Statistische Tests 2 Statistische Tests 1 Schätzen von Verteilungsparametern 2 in R 11 Statistische Tests 3 Statistische Tests 2 F- und t-Test 12 Lineare Regression 1 Statistische Tests 3 Kolmogorow-Smirnow- und Chi-Quadrat-Test 13 Lineare Regression 2 Lineare Regression 1 Lineare Regression 1 “per Hand” in R 14 Klausurvorbereitung Lineare Regression 2 Lineare Regression 2 “per Hand” in R 15 Statistik hinterfragen Klausurvorbereitung Lineare Regression 3 in R Der prinzipielle Lernmodus in diesem digitalen Semester ist das Lesen von Kapiteln aus dem vorliegenden Skript und aus zwei Lehrbüchern (Zimmermann-Janschitz (2014) und Mittag (2016)). Dazu gibt es kleine Quizzes jede Woche. Diese werden automatisch bewertet und sind Voraussetzung für den Erhalt der 3 Leistungspunkte des Seminars Einführung in die Statistik. Im Seminar jeden Montag besteht die Möglichkeit, Fragen zu klären und den Stoff der vorherigen Woche zu diskutieren. Das Seminar findet über ZOOM statt - s. permanenter link auf Moodle. Wichtig: Fragen und Diskussionswünsche müssen bis Ende jeder Woche über das Moodleforum eingereicht werden. Manche Fragen werden sich bereits über das Forum klären lassen. Im Selbststudium - unterstützt durch das Seminar - erarbeiten Sie sich so die Theorie, welche dann in der PC-Übung mittels der Software R zur Anwendung kommt. Die PC-Übung findet ab 27. November immer freitags 09:00-12:00 statt, ebenfalls über ZOOM. Wir werden mehrere thematische ZOOM-Räume anbieten, in die Sie nach Bedarf gehen können (Fragen zu Hausaufgaben, Fragen zu R, Fragen zur Theorie, …). In diesem Zeitfenster bearbeiten Sie jede Woche einen Übungszettel. Die Lehrende stehen während dessen in den ZOOM-Räumen für Fragen zur Verfügung. Ein Lösungszettel wird am Ende bereit gestellt. Abschließend gibt es eine neue Hausaufgabe bis zur nächsten Woche. Der Lösungszettel wird vor der nächsten Übung bereit gestellt. Außerhalb des Zeitfensters am Freitag beantworten wir Fragen über das Moodle Forum. In den Hausaufgaben wird in der Übung Erprobtes auf einen anderen Datensatz angewendet oder erweitert. Die Hausaufgaben sind Voraussetzung für den Erhalt der 3 Leistungspunkte der PC-Übung Statistische Datenverarbeitung. Die Abgabe erfolgt über einen Abgabelink auf Moodle bis zum nächsten Mittwoch 24:00. Das Abgabeformat (HTML via R Markdown) wird in der ersten PC-Übung ausführlich erklärt und eingeübt. Es beinhaltet den R-Code, einen kurzen Text zur Beantwortung der Fragestellung bzw. Interpretation der Ergebnisse, sowie relevante (!) Abbildungen, Tabellen und Kenngrößen. Am Donnerstag wird das Lösungsblatt bereit gestellt. Unklarheiten und Probleme werden während der nächsten Übung geklärt (eigener ZOOM-Raum). Ein kurzes Wort zu unseren Erwartungen: In diesem digitalen Semester wird selbständiges Lernen noch wichtiger sein als in Präsenzsemestern. Das Seminar entspricht mit 3 Leistungspunkten einem Aufwand von 90 Stunden, d.h. 6 Stunden pro Woche. Bei maximal 1,5 Stunden “Präsenz” via ZOOM verbleiben mindestens 4,5 Stunden pro Woche für das Selbststudium des Skriptes und der ausgewählten Lehrbuchkapitel. Die PC-Übung entspricht mit 3 Leistungspunkten ebenfalls 90 Stunden, d.h. 7,5 Stunden pro Woche ab Semesterwoche 4. Bei 3 Stunden “Präsenz” via ZOOM verbleiben weitere 4,5 Stunden pro Woche für Nachbereitung und Hausaufgaben. Insgesamt sollten Sie sich also auf 9 Stunden pro Woche selbstständiges Arbeiten für Statistik einstellen. Die Modulabschlussprüfung ist dieses Jahr eine sogenannte take-home Klausur, die Sie - voraussichtlich in der 1. Semesterferienwoche - zuhause in einem vorgegeben Zeitrahmen selbständig bearbeiten. Ein Nachholtermin findet voraussichtlich in der letzten Semesterferienwoche statt. Die Anmeldung erfolgt gegen Semesterende über AGNES bei Frau Schwedler. Die take-home Klausur wird stark an die Übungen und Hausaufgaben angelehnt sein. Dazu wird es ein paar Fragen über Moodle geben - ähnlich der regelmäßigen Quizzes. Insgesamt werden sich 5/6 der zu erreichenden Punktzahl auf Einführung in die Statistik beziehen und 1/6 auf Einführung in die Geographie. 1.4 Mathematische Notation und Grundlagen In diesem Unterkapitel werden wichtige Begriffe eingeführt und wichtige mathematische Grundlagen aus der Schule wiederholt. Lesen Sie bitte dazu Kapitel 1.2 von Zimmermann-Janschitz (2014). Dort werden anhand des Beispieles der Kostenaufstellung für eine “Statistikexkursion” die Begriffe Variable, Index und Summe eingeführt. Variable wird synonym mit Merkmal verwendet. In den Zeilen der Tabelle 1.1 in Zimmermann-Janschitz (2014) stehen dann die einzelnen Merkmalswerte oder einfach nur Werte für die Untersuchungselemente (statistische Einheiten). Jede statistische Einheit ist gekennzeichnet durch einen eigenen Index. An dieser Stelle sei ergänzt, dass ein Index auch unterschiedliche Variablen bezeichnen kann, z.B. \\(x_1, x_2, \\ldots\\). Die Summe verschiedener Merkmalswerte wird wie folgt abgekürzt: \\[\\begin{equation} \\sum_{i=1}^{n}x_i=x_1+x_2+\\ldots+x_{n-1}+x_n \\tag{1.1} \\end{equation}\\] Wobei das Summenzeichen \\(\\Sigma\\) die Anweisung symbolisiert, die Merkmalswerte \\(x_i\\) zu addieren, wobei der Index \\(i\\) von 1 bis zur Anzahl der Werte \\(n\\) läuft. Eine ähnliche verkürzte Schreibweise gibt es für das Produkt: \\[\\begin{equation} \\prod_{i=1}^{n}x_i=x_1 \\cdot x_2 \\cdot \\ldots \\cdot x_{n-1} \\cdot x_n \\tag{1.2} \\end{equation}\\] Hier gibt das Produktzeichen \\(\\Pi\\) die Anweisung, die Merkmalswerte \\(x_i\\) zu multiplizieren, wobei wiederum der Index \\(i\\) von 1 bis zur Anzahl der Werte \\(n\\) läuft. Manchmal wird das Multiplikationszeichen weggelassen und es findet sich nur ein kleiner Abstand zwischen den zu multiplizierenden Größen: \\[\\begin{equation} \\prod_{i=1}^{n}x_i=x_1 \\, x_2 \\, \\ldots \\, x_{n-1} \\, x_n \\tag{1.3} \\end{equation}\\] Diese Schreibweise, die man häufig aus Platzgründen findet, impliziert in jedem Fall eine Multiplikation. Zwei weitere Begriffe, die Zimmermann-Janschitz (2014) nicht einführt, sind für diese Lehrveranstaltung noch wichtig, Vektor und Matrix: In einem Reihenvektor sind Größen (z.B. Merkmalswerte) horizontal angeordnet: \\[\\mathbf{x} = \\begin{pmatrix} x_1 &amp; x_2 &amp; \\cdots &amp; x_n \\end{pmatrix}\\] In einem Spaltevektor sind die Größen vertikal angeordnet: \\[\\mathbf{x} = \\begin{pmatrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{pmatrix}\\] In einer Matrix sind Größen wie in einer Tabelle angeordnet, z.B. Merkmalswerte unterschiedlicher Variablen (Spalten): \\[\\mathbf{X} = \\begin{pmatrix} x_{1,1} &amp; x_{1,2} &amp; \\cdots &amp; x_{1,p}\\\\ x_{2,1} &amp; x_{2,2} &amp; \\cdots &amp; x_{2,p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ x_{n,1} &amp; x_{n,2} &amp; \\cdots &amp; x_{n,p} \\end{pmatrix}\\] Hier hat jeder Merkmalswert zwei Indices, einen für die statistische Einheit (hier bis Anzahl \\(n\\)) und einen für die Variable (hier bis Anzahl \\(p\\)). Vektoren und Matrizen werden in der Regel fett gedruckt, wobei Vektoren mit Kleinbuchstaben und Matrizen mit Großbuchstaben bezeichnet werden. Die Rechenregeln für Vektoren und Matrizen sind in der linearen Algebra zusammengefasst. Wir werden daraus nur Auszüge in den letzten Semesterwochen verwenden. Aufgabe: Zu diesen Begriffen gibt es ebenfalls ein kleines Quiz zu beantworten - s. Moodle unter Woche 1. 1.4.1 Exponential- und Logarithmusfunktion Zwei mathematische Funktionen sind für diese Lehrveranstaltung besonders wichtig, die Exponential- und die Logarithmusfunktion. Die folgende Darstellung ist inspiriert von Gelman and Nolan (2002). Stellen Sie sich eine Amöbe vor, die sich innerhalb einer Stunde teilt (Abbildung 1.1). Diese zwei Amöben teilen sich jede in einer weiteren Stunde usw. Wie lautet die Gleichung für die Anzahl Amöben, \\(y\\), als Funktion der Zeit, \\(t\\) (in Stunden)? Figure 1.1: Sich teilende Amöbe. Quelle: http://www.gutenberg.org/files/18451/18451-h/images/illus002.jpg. Die Gleichung lautet: \\[\\begin{equation} y=2^t \\tag{1.4} \\end{equation}\\] Dies ist eine Exponentialfunktion mit Basis 2 and Exponent \\(t\\). Abbildung 1.2 zeigt zwei Plots dieser Funktion. (Den verwendeten R code werden sie im Verlauf der PC-Übung verstehen.) t &lt;- seq(1, 6) y &lt;- 2^t plot(t, y, pch = 19, type = &#39;b&#39;) plot(t, log(y), pch = 19, type = &#39;b&#39;) Figure 1.2: Links: Plot von Gleichung 1.4. Right: Plot von Gleichung 1.4 auf logarithmischer Skala. Die Umkehrfunktion der Exponentialfunktion ist die Logarithmusfunktion: \\[\\begin{equation} log(y)=log(2^t)=t \\cdot log(2) \\tag{1.5} \\end{equation}\\] Da der Logarithmus von \\(y\\) eine lineare Funktion von \\(t\\) ist (Gleichung (1.5)), zeigt die rechte Seite von Abbildung 1.2 (\\(y\\) auf logarithmischer Skala) eine gerade Linie. Übliche Basen der Logarithmusfunktion sind: \\[\\begin{equation} log_2\\left(2^t\\right)=lb\\left(2^t\\right)=t \\tag{1.6} \\end{equation}\\] Dies ist der sogenannte binäre Logarithmus (lb). \\[\\begin{equation} log_{10}\\left(10^t\\right)=lg\\left(10^t\\right)=t \\tag{1.7} \\end{equation}\\] Dies ist der sogenannte dekadische Logarithmus (lg). \\[\\begin{equation} log_e\\left(e^t\\right)=ln\\left(e^t\\right)=t \\tag{1.8} \\end{equation}\\] Dies ist der sogenannte natürliche Logarithmus (ln), wobei \\(e \\approx 2.7183\\) die Eulersche Zahl ist. Achtung: Programmiersprachen wie R nutzen oft eine andere Notation, der wir auch in diesem Kurs folgen: \\[\\begin{equation} ln()=log() \\tag{1.9} \\end{equation}\\] \\[\\begin{equation} e^t=\\exp(t) \\tag{1.10} \\end{equation}\\] Die Rechenregeln der Exponentialfunktion sind: \\[\\begin{equation} a^m \\cdot a^n=a^{m+n} \\tag{1.11} \\end{equation}\\] \\[\\begin{equation} a^n \\cdot b^n=(a \\cdot b)^n \\tag{1.12} \\end{equation}\\] \\[\\begin{equation} \\frac{a^m}{a^n}=a^{m-n} \\tag{1.13} \\end{equation}\\] \\[\\begin{equation} \\frac{a^n}{b^n}=\\left(\\frac{a}{b}\\right)^n \\tag{1.14} \\end{equation}\\] \\[\\begin{equation} \\left(a^m\\right)^n=a^{m \\cdot n} \\tag{1.15} \\end{equation}\\] Die Rechenregeln der Logarithmusfunktion sind: \\[\\begin{equation} log(u \\cdot v)=log(u)+log(v) \\tag{1.16} \\end{equation}\\] \\[\\begin{equation} log\\left(\\frac{u}{v}\\right)=log(u)-log(v) \\tag{1.17} \\end{equation}\\] \\[\\begin{equation} log\\left(u^r\\right)=r \\cdot log(u) \\tag{1.18} \\end{equation}\\] 1.4.2 Quadratische Funktion und Wurzelfunktion Abschließend sei noch die quadratische Funktion erwähnt (Abbildung 1.3, links): \\[\\begin{equation} f(x)=x^2 \\tag{1.19} \\end{equation}\\] x &lt;- seq(0, 5, 0.1) plot(x, x^2, pch = 19, type = &#39;b&#39;) plot(x, sqrt(x^2), pch = 19, type = &#39;b&#39;) Figure 1.3: Links: Quadratische Funktion von \\(x\\). Right: Wurzelfunktion von \\(x^2\\) (Gleichung 1.20). Und ihre Umkehrfunktion, die Wurzelfunktion (Abbildung 1.3, rechts): \\[\\begin{equation} \\sqrt{x^2}=x \\tag{1.20} \\end{equation}\\] Literatur "],
["begriffe.html", "Chapter 2 Grundbegriffe und Datenerhebung 2.1 Statistische Grundbegriffe 2.2 Datenerhebung 2.3 Skalenniveaus", " Chapter 2 Grundbegriffe und Datenerhebung Lesen Sie hierzu bitte Kapitel 3.1.2 und 3.1.3 von Zimmermann-Janschitz (2014). Im folgenden finden Sie Leitfragen und Ergänzungen zu diesen Kapiteln. 2.1 Statistische Grundbegriffe Die statistische Masse umfasst all jene Elemente (Anzahl \\(N\\)), die für eine statistische Untersuchung Relevanz besitzen. Für die Bestimmung der statistischen Masse sind inhaltliche, zeitliche und räumliche Abgrenzungskriterien erforderlich. Alternative Begriffe sind (die geläufigsten fett gedruckt): statistische Grundmenge, Grundgesamtheit, Population, Kollektiv. Beispiele finden Sie in Zimmermann-Janschitz (2014), Kapitel 3.1.3. Die statistische Einheit \\(e_i\\) mit \\(i=1, \\ldots, n\\) stellt das Untersuchungselement und somit die kleinste, nicht weiter unterteilbare Einheit in einer statistischen Untersuchung dar. Diese statistische Einheit trägt jene Information (auch als Merkmal \\(x\\) bezeichnet), die im Zentrum der statistischen Untersuchung steht. Alternative Begriffe sind, je nach Kontext: Untersuchungseinheit, Proband, Merkmalsträger. Siehe Zimmermann-Janschitz (2014), Kapitel 3.1.3 für Beispiele. Jene Eigenschaft eines Untersuchungselements, die für die statistische Untersuchung von Bedeutung ist, wird als Merkmal \\(x\\) des Elements bezeichnet. Eine statistische Einheit weist mindestens ein Merkmal auf, kann aber ebenso durch mehrere Merkmale gekennzeichnet sein. Alternative Begriffe sind: Variable, Indikator. Beispiele finden Sie wiederum in Zimmermann-Janschitz (2014), Kapitel 3.1.3. Die Merkmalsausprägungen \\(a_j\\) mit \\(j=1, \\ldots, m\\) eines Merkmals \\(x\\) umfassen jene Manifestationen, die ein Merkmal im Rahmen einer statistischen Untersuchung annehmen kann. Alternative Begriffe sind: Merkmalskategorien, Modalitäten. Z.B. kann das Merkmal Schneedeckenhöhe Werte von null (kein Schnee vorhanden) bis zu mehreren Metern einnehmen. Der Merkmalswert \\(x_i\\) mit \\(i=1, \\ldots, n\\) schließlich ist jener Wert, den ein Merkmal \\(x\\) in einer statistischen Untersuchung tatsächlich annimmt. Alternative Begriffe sind: Beobachtungswert, Datum (Plural: Daten). Beispiel: Tatsächliche Schneedeckenmessung an einem Punkt von 285,5cm. 2.2 Datenerhebung Leitfragen zu Zimmermann-Janschitz (2014), Kapitel 3.1.2: Was ist der Unterschied zwischen Primärdaten und Sekundärdaten? Was sind die Vor- und Nachteile? Was sind Metadaten? Wozu sind sie wichtig? Was ist der Unterschied zwischen Gesamterhebung und Teilerhebung? Zur Primärdatenerhebung hören Sie mehr von Henning Nuissl im Seminar Einführung in die Geographie. An dieser Stelle aber noch ein paar Worte zur Auswahl einer Stichprobe aus einer Grundgesamtheit. Aus statistischer Perspektive sind dabei prinzipiell drei Aspekte zu beachten: Repräsentativität: Eine Stichprobe sollte die Variabilität der Grundgesamtheit möglichst genau abbilden, z.B. bezüglich Demographien oder räumlicher Unterschiede. Zufälligkeit: Jede Merkmalsausprägung der Grundgesamtheit sollte die gleiche “Chance” haben ausgewählt zu werden. In der Praxis ist dies oft nur näherungsweise möglich. Stichprobenumfang: Eine Stichprobe sollte ausreichend groß sein. Mehr dazu in der schließenden Statistik (Kapitel 8-12). 2.3 Skalenniveaus Die Skalenniveaus von Daten bestimmen den Informationsgehalt der Daten und damit das Analyse- und Interpretationspotenzial. In der Reihenfolge Nominalskala - Ordinalskala - metrische Skalen werden jeweils zusätzliche mathematische Operationen erschlossen (s. Zimmermann-Janschitz (2014), Tabelle 3.8, S. 79). Qualitative, klassifikatorische Merkmale befinden sich auf der Nominalskala. Die Kategorien können verbale Bezeichnungen oder Zahlencodes sein (Achtung: Die Zahl ist in dem Fall ein Code und keine natürliche Zahl mit der gerechnet werden kann.) Die zulässige mathematische Operation ist der Vergleich, d.h. Merkmalswerte von statistischen Einheiten sind entweder gleich oder verschieden. Beispiel: Art des Vulkanausbruchs (Tabelle 2.1). Obwohl \\(1+2=3\\) ist, ist Lava plus Gestein nicht gleich Gas! Table 2.1: Art des Vulkanausbruchs. Lava Gestein Gas Asche 1 2 3 4 Qualitative, komparative Merkmale (Rangmerkmale) finden Sie auf der Ordinalskala. Wieder können die Kategorien verbale Bezeichnungen sein oder mittels Zahlen codiert. Die Zulässigen mathematischen Operationen sind der Vergleich sowie Wertung/Reihung/Ordnung. Es sind keine Aussagen über Distanz oder Ähnlichkeit benachbarter Merkmalsausprägungen möglich. Beispiel: Komfort der Unterkunft (Tabelle 2.2). Der Komfort eines ***Hotels ist größer als der Komfort eines *Hotels, aber nicht 3x so groß! Table 2.2: Komfort der Unterkunft. Jugendherberge *Hotel **Hotel ***Hotel 0 1 2 3 Quantitative Merkmale befinden sich auf metrischen Skalen. Sie werden mit reellen Zahlen bezeichnet. Die zulässigen mathematischen Operationen sind der Vergleich, Wertung/Reihung/Ordnung sowie Addition/Subtraktion und im Falle der Rationalskala auch Multiplikation/Division. Die Unterscheidung Intervallskala und Rationalskala (Verhältnisskala) ist für uns nicht so wichtig. Intervallskalen fehlt ein natürlicher Nullpunkt und daher ist die Berechnung von Relationen nicht möglich. Sie kann aber auf einen Referenznullpunkt umgerechnet werden, wodurch Multiplikation und Division möglich wedren. Wenn wir also in diesem Kurs von einer metrischen Skala sprechen dann sind die mathematischen Operationen Vergleich, Wertung/Reihung/Ordnung, Addition/Subtraktion und Multiplikation/Division alle zulässig. Literatur "],
["haeufigkeit.html", "Chapter 3 Häufigkeiten und Lageparameter 3.1 Ziel der deskriptiven Statistik 3.2 Häufigkeiten 3.3 Lageparameter", " Chapter 3 Häufigkeiten und Lageparameter Mit diesem Kapitel des Skriptes steigen wir in die deskriptive Statistik ein. Lesen Sie hierzu bitte Kapitel 3.2.1 und 3.2.2 von Zimmermann-Janschitz (2014). Im folgenden finden Sie wie gehabt Leitfragen und Ergänzungen zu diesen Kapiteln. 3.1 Ziel der deskriptiven Statistik Jene Eigenschaft eines Untersuchungselements, die für die statistische Untersuchung von Bedeutung ist, wird als Merkmal \\(x\\) des Elements bezeichnet. Der Merkmalswert \\(x_i\\) mit \\(i=1,\\ldots,n\\) ist jener Wert, den ein Merkmal \\(x\\) in einer statistischen Untersuchung tatsächlich annimmt. Ziel der deskriptiven Statistik ist es, die Verteilung der Merkmalswerte eines Merkmals über den möglichen Wertebereich (Ausprägungen) mit einzelnen Parametern näher zu charakterisieren. Z.B. die Anzahl der Ausbrüche eines Vulkans an verschiedenen Tagen. Die Parameter sind: Lageparameter: Maße der zentralen Tendenz einer Verteilung (s. dieses Kapitel) Streuungsparameter: Maße der Variabilität einer Verteilung (s. Kapitel 4) Schiefe und Wölbung einer Verteilung (s. Kapitel 4) Dazu brauchen wir erstmal Begriffe wie absolute Häufigkeit, relative Häufigkeit und Summenhäufigkeit sowie Diagramme wie Histogramme und Boxplots, die Verteilungen graphisch darstellen. 3.2 Häufigkeiten Schauen wir uns dazu die Reisedaten an, die die Studierenden im letzte Jahr eingegeben hatten, und zwar nur die Entfernungen (der R-Code wird in den PC-Übungen schnell klar werden): # Ausgabe von dat$x # dies ist die Variable &quot;Entfernung (Luftlinie) zum Wohnort (m)&quot; dat$x ## [1] 11000.00 11080.00 4130.00 32630.00 12000.00 10180.00 5100.00 14380.00 ## [9] NA 18710.00 16341.00 12820.00 7370.00 NA 17630.00 13750.00 ## [17] 13070.00 15300.00 15150.00 20200.00 3890.00 NA NA 15770.00 ## [25] 11630.00 27300.00 8150.00 NA 9580.00 31310.00 NA 21030.00 ## [33] 9790.00 NA 23240.00 8640.00 12620.00 12045.00 10079.00 11200.00 ## [41] 52320.00 11200.00 13290.00 10220.00 1572.00 28580.00 15740.00 10110.00 ## [49] 15220.00 8900.00 1900.00 9650.00 11390.00 9360.00 3000.00 11376.00 ## [57] 12890.00 2500.00 NA 16760.00 18450.00 4570.00 15050.00 14300.00 ## [65] 13260.00 7950.00 NA 15730.00 NA 17830.00 10500.00 517.45 ## [73] 4780.00 13910.00 1027.00 9900.00 17000.00 13065.00 16930.00 16200.00 ## [81] 14420.00 NA 17380.00 6040.00 NA 10800.00 4365.00 15691.00 ## [89] 19520.00 29610.00 13480.00 15940.00 NA NA NA 13350.00 ## [97] 16350.00 3750.00 18000.00 12800.00 3710.00 32000.00 17760.00 4130.00 ## [105] 26560.00 13000.00 12000.00 27470.00 14980.00 10210.00 17440.00 3090.00 ## [113] 9000.00 25070.00 6990.00 6170.00 14470.00 10700.00 39510.00 17430.00 ## [121] 25360.00 21000.00 Das ist eine ungeordnete Reihe von 122 Datenpunkten, die sogenannten Rohdaten. “NA” steht für “not available”, d.h. fehlende Daten. Wenn wir die Rohdaten jetzt ordnen und in Klassen einteilen können wir absolute Häufigkeiten bestimmen, gewissermaßen durch Abzählen: # dat$x aufsteigend ordnen und ausgeben sort(dat$x) ## [1] 517.45 1027.00 1572.00 1900.00 2500.00 3000.00 3090.00 3710.00 ## [9] 3750.00 3890.00 4130.00 4130.00 4365.00 4570.00 4780.00 5100.00 ## [17] 6040.00 6170.00 6990.00 7370.00 7950.00 8150.00 8640.00 8900.00 ## [25] 9000.00 9360.00 9580.00 9650.00 9790.00 9900.00 10079.00 10110.00 ## [33] 10180.00 10210.00 10220.00 10500.00 10700.00 10800.00 11000.00 11080.00 ## [41] 11200.00 11200.00 11376.00 11390.00 11630.00 12000.00 12000.00 12045.00 ## [49] 12620.00 12800.00 12820.00 12890.00 13000.00 13065.00 13070.00 13260.00 ## [57] 13290.00 13350.00 13480.00 13750.00 13910.00 14300.00 14380.00 14420.00 ## [65] 14470.00 14980.00 15050.00 15150.00 15220.00 15300.00 15691.00 15730.00 ## [73] 15740.00 15770.00 15940.00 16200.00 16341.00 16350.00 16760.00 16930.00 ## [81] 17000.00 17380.00 17430.00 17440.00 17630.00 17760.00 17830.00 18000.00 ## [89] 18450.00 18710.00 19520.00 20200.00 21000.00 21030.00 23240.00 25070.00 ## [97] 25360.00 26560.00 27300.00 27470.00 28580.00 29610.00 31310.00 32000.00 ## [105] 32630.00 39510.00 52320.00 # Daten in km umrechnen und absolute Häufigkeiten bestimmen # für Klassen von 0 bis 55km mit Breite 5km hist(dat$x/1000, breaks = seq(0, 55, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) Diese Darstellung ist ein Histogramm. Dazu später mehr. Das Ordnen geschieht bei der Erechnung des Histogramms automatisch, hier haben wir es nur der Anschaulichkeit halber eingefügt. Die absolute Häufigkeit, bezeichnet mit \\(h_j\\) für \\(h\\left(a_j\\right)\\) und \\(j=1,\\ldots,m\\), gibt also die Anzahl der statistischen Einheiten in einer Stichprobe an, welche die Merkmalsausprägung \\(a_j\\) für ein Merkmal \\(x\\) annehmen. In unserem Beispiel haben wir die Merkmalsausprägungen durch Klassifizierung gewissermaßen künstlich erzeugt da die Menge der Ausprägungen des Merkmals “Entfernung” ja nicht abzählbar ist. Im Beispiel der Anzahl Vulkanausbrüche in Zimmermann-Janschitz (2014) gibt es dagegen abzählbare Merkmalsausprägungen. Die Summe der absoluten Häufigkeiten ist der Stichprobenumfang \\(n\\): \\[\\sum_{j=1}^{m}h_j=n \\quad\\text{mit}\\quad m\\leq n\\] Die relative Häufigkeit, bezeichnet mit \\(f_j\\) für \\(f\\left(a_j\\right)\\) und \\(j=1,\\ldots,m\\), gibt dann den Anteil der statistischen Einheiten an einer Stichprobe an, welche die Merkmalsausprägung \\(a_j\\) für ein Merkmal \\(x\\) annehmen: \\[f_j=f\\left(a_j\\right)=\\frac{h\\left(a_j\\right)}{n}\\] Das Histogramm bleibt gleich, nur dass die vertikale Achse anders skaliert ist. Da das in der hist() Funktion nicht vorgesehen ist, ist der R-Code etwas länger: # Histogramm berechnen ohne Output h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) # absolute in relative Häufigkeiten umrechnen h$counts &lt;- h$counts / sum(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;relative Häufigkeit&quot;) Interpretation: Der ersten Balken z.B. geht bis knapp unter 0.15, d.h. knapp 15% der Entfernungsdaten haben Werte zwischen 0 und 5km. Wenn wir uns das Histogramm der absoluten Häufigkeiten weiter oben anschauen dann sehen wir, dass das etwa 15 von 107 Datenpunkten (ohne “NA”) sind. Die Summe der relativen Häufigkeiten ist 1, was 100% entspricht: \\[\\sum_{j=1}^{m}f_j=1 \\quad\\text{mit}\\quad m\\leq n\\] Kommen wir nun zu den Summenhäufigkeiten, auch genannt kumulative Häufigkeit oder kumulierte Häufigkeit. Die absolute Summenhäufigkeit einer Merkmalsausprägung \\(a_j\\) ist die Anzahl der Merkmalswerte, die kleiner oder gleich \\(a_j\\) sind. Die relative Summenhäufigkeit von \\(a_j\\) ist dementsprechend der Anteil der Merkmalswerte, die kleiner oder gleich \\(a_j\\) sind. Am besten visualisieren wir das kurz in R: # Histogramm berechnen ohne Output h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) # Häufigkeiten kumuliert aufsummieren h$counts &lt;- cumsum(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Summenhäufigkeit&quot;) # absolute Summenhäufigkeiten in relative umrechnen h$counts &lt;- h$counts / max(h$counts) # Histogrammdaten plotten plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;relative Summenhäufigkeit&quot;) Die Häufigkeiten der Klassen sind hier kumuliert aufsummiert, d.h. der letzte Balken ganz rechts hat die absolute Höhe 107, die Gesamtzahl der Datenpunkte \\(n\\) (ohne “NA”), bzw. die relative Höhe 1 (100%). Sehen die dazu auch das Beispiel in Zimmermann-Janschitz (2014), Tabelle 3.10 auf Seite 87. Abschließend noch ein paar Worte zur Klassifizierung. Äquidistante Klassen, d.h. Klassen gleicher Breite, sind grundsätzlich zu bevorzugen. In R können Sie eine gewünschte Anzahl Klassen angeben, die dann äquidistant über den Wertebereich verteilt werden. Das ist sinnvoll für einen ersten Eindruck. Die Grundeinstellung von 10 Klassen ist dabei meist ausreichend. Im Laufe der Analyse wird es manchmal sinnvoller sein, bestimmte Klassen vorzugeben, auch (oder gerade) wenn manche Klasse in der betrachteten Stichprobe nicht vorkommen. Auch das ist in R möglich, in dem Sie die Klassengrenzen (“breaks”) angeben. Probieren wir das in R aus: # Klassenbreite 5km hist(dat$x/1000, breaks = seq(0, 60, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) # Klassenbreite 10km hist(dat$x/1000, breaks = seq(0, 60, 10), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) # Klassenbreite 20km hist(dat$x/1000, breaks = seq(0, 60, 20), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) Je größer die Klassenbreite desto mehr Nuancen der Verteilung der Werte geht verloren. Je kleiner die Klassenbreite desto mehr Lücken entstehen im Histogramm und die generelle Form der Verteilung tritt in den Hintergrund. Eine geeignete mittlere Klassenbreite wird man nur durch Ausprobieren hinbekommen. Siehe aber Zimmermann-Janschitz (2014), S. 91-102 für Richtlinien zur Klassenbildung. 3.3 Lageparameter Lageparameter sind Maße der zentralen Tendenz einer Häufigkeitsverteilung. Siehe Zimmermann-Janschitz (2014), Kapitel 3.2.2. Wichtig sind uns in dieser Veranstaltung der Modus, das arithmetische Mittel und der Median, weniger das harmonische Mittel und das geometrische Mittel, die Sie aber bei Zimmermann-Janschitz (2014) nachlesen können. Der Modus \\(\\bar x_{mod}\\) entspricht jener Merkmalsausprägung \\(a_j\\), die in der Häufigkeitsverteilung (lokal) am häufigsten vorkommt. In unseren Entfernungsdaten wäre das der Wert 12.5: h &lt;- hist(dat$x/1000, breaks = seq(0, 55, 5), plot = FALSE) plot(h, freq = TRUE, col = &quot;gray&quot;, main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) # Gib Klassenmitte aus an der Stelle wo die Häufigkeiten gleich dem Maximum sind h$mids[h$counts==max(h$counts)] ## [1] 12.5 Bei “künstlichen” Klassen wie in unserem Beispiel wird typischerweise die Mitte der häufigsten Klasse angegeben. Sie sehen also, der Modus ist in diesem Fall abhängig von der gewählten Klassifizierung und nicht eindeutig. In der obigen Darstellung sehen wir außerdem ein zweites lokales Maximum bei 27.5, es handelt sich also in dieser Klassifizierung um eine bimodale Verteilung. Der generelle Begriff für mehrere Modi ist multimodal. Das arithmetische Mittel \\(\\bar x\\) der Merkmalswerte \\(x_1, x_2, \\ldots, x_n\\) ist die Summe aller Merkmalswerte \\(x_i\\) relative zur Stichprobengröße \\(n\\): \\[\\bar x=\\frac{\\sum_{i=1}^{n}x_i}{n}\\] Liegen absolute oder relative Häufigkeiten für die Merkmalsausprägungen \\(a_j\\) vor, kann das arithmetische Mittel \\(\\bar x\\) gewichtet berechnet werden: \\[\\bar x=\\frac{\\sum_{j=1}^{m}a_j\\cdot h_j}{n}=\\sum_{j=1}^{m}a_j\\cdot f_j\\quad\\text{mit}\\quad m\\leq n\\] Berechnen wir das arithmetische Mittel für unsere Entfernungsdaten mit der Funktion mean: # berechne arithmetisches Mittel für Variable &quot;Entfernung&quot; (x) in km, # wobei &quot;NA&quot; Werte ignoriert werden sollen (sonst wäre die Ausgabe ebenfalls &quot;NA&quot;) mean(dat$x/1000, na.rm = TRUE) ## [1] 13.95896 Andere Mittelwerte sind das geometrische Mittel und das harmonische Mittel, siehe Zimmermann-Janschitz (2014), S. 126-134. Der Median \\(\\bar x_{med}\\) schließlich entspricht jenem Merkmalswert \\(x_j\\) in einer Häufigkeitsverteilung, der eine geordnete Reihe von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) in zwei gleich große Wertebereiche teilt. Für eine ungerade Anzahl von Merkmalswerten entspricht der Median dem mittleren Wert: \\[\\bar x_{med}=x_{\\frac{n+1}{2}}\\] Für eine gerade Anzahl von Merkmalswerten wird der Median aus dem arithmetischen Mittel der beiden mittleren Werte errechnet: \\[\\bar x_{med}=\\frac{x_{\\frac{n}{2}}+x_{\\frac{n}{2}+1}}{2}\\] Berechnen wir den Median für unsere Entfernungsdaten mit der Funktion median: median(dat$x/1000, na.rm = TRUE) ## [1] 13.065 Der Median wird auch 0,5-Quantil genannt. Allgemein entspricht ein p-Quantil \\(\\bar x_p\\) mit \\(0\\leq p\\leq 1\\) jenem Merkmalswert \\(x_j\\) in einer Häufigkeitsverteilung, der eine geordnete Reihe von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) in zwei Wertebereiche teilt, so dass ein Anteil \\(p\\) der Werte kleiner oder gleich \\(x_j\\) ist. Ist das Produkt \\(n\\cdot p\\) nicht ganzzahlig, wird für \\(j\\) die dem Produkt nächstgrößere Zahl verwendet: \\[\\bar x_p=x_j\\] Ist das Produkt \\(n\\cdot p\\) ganzzahlig, dann ist \\(j=n\\cdot p\\): \\[\\bar x_p=\\frac{x_j+x_{j+1}}{2}\\] Auf Quantile werden wir im Zuge theoretischer Verteilungen noch näher zu sprechen kommen (Kapitel 7). Literatur "],
["streuung.html", "Chapter 4 Streuungsparameter, Schiefe und Wölbung 4.1 Streuungsparameter 4.2 Schiefe und Wölbung von Häufigkeitsverteilungen", " Chapter 4 Streuungsparameter, Schiefe und Wölbung 4.1 Streuungsparameter Lesen Sie dazu bitte Kapitel 3.2.3 von Zimmermann-Janschitz (2014). Streuungsparameter sind Maße der Variabilität einer Häufigkeitsverteilung. Uns interessieren hier v.a. Spannweite, Quartilsabstand, Varianz und Standardabweichung und Variationskoeffizient, weniger durchschnittliche absolute Abweichung, da wir leztere kaum in der Praxis sehen. Spannweite und Quartilsabstand lassen sich am besten mit einem sogenannten Box-Whisker-Plot, kurz einfach Boxplot, verdeutlichen (Abbildung 4.1). Ein Boxplot fasst die Verteilung der Werte eines Merkmals (in einer Stichprobe) zusammen. Die Spannweite ist der Abstand zwischen Minimum und Maximum der Merkmalswerte. Der Quartilsabstand ist der Abstand zwischen 0,25-Quantil und 0,75-Quantil; in diesem Bereich liegen 50% der Merkmalswerte (0,75-0,25). 0,25-Quantil, 0,5-Quantil (Median) und 0,75-Quantil heissen auch 1., 2. und 3. Quartil, weil sie den Wertebereich in vier gleichgroße Teile teilen: Zwischen Minimum und 0,25-Quantil liegen 25% der Merkmalswerte, zwischen 0,25-Quantil und Median 25%, zwischen Median und 0,75-Quantil 25% und zwischen 0,75-Quantil und Maximum ebenfalls 25%. Ebenso gibt es auch Quintile usw., diese sind aber in der Praxis kaum von Bedeutung. Ein Boxplot kann horizontal wie hier und vertikal dargestellt werden. Figure 4.1: Boxplot mit Quartilsabstand und Spannweite. Der Boxplot ist eine vereinfachte Darstellung eines Histogramms. Schauen Sie sich dazu bitte Kapitel 4.3.6 von Zimmermann-Janschitz (2014) an, besonders Abbildung 4.10. Sehen Sie welcher Boxplot in 4.10b zu welchem Histogramm in 4.10c gehört? Die Entsprechung können Sie auch in unseren Reisedaten sehen (hier sowohl “Entfernung” als auch “Reisezeit”): # Histogramm &quot;Entfernung&quot; in km hist(dat$x/1000, breaks = seq(0, 55, 5), main = &quot;&quot;, xlab = &quot;Entfernung (km)&quot;, ylab = &quot;absolute Häufigkeit&quot;) # Histogramm &quot;Reisezeit&quot; in min hist(dat$t, breaks = seq(0, 120, 10), main = &quot;&quot;, xlab = &quot;Reisezeit (min)&quot;, ylab = &quot;absolute Häufigkeit&quot;) # Boxplot &quot;Entfernung&quot; in km boxplot(dat$x/1000, range = 0, horizontal = TRUE, ylim = c(0,55), xlab = &quot;Entfernung (km)&quot;) # Boxplot &quot;Reisezeit&quot; in min boxplot(dat$t, range = 0, horizontal = TRUE, ylim = c(0,120), xlab = &quot;Reisezeit (min)&quot;) “Entfernung” ist schief verteilt, die zentralen 50% der Verteilung - die “Box” im Boxplot - befinden sich links der Mitte. “Reisezeit” dagegen ist annähernd symmetrisch verteilt, mit der Box in Mitte des Plots. Es ist wichtig für das Verständnis von Verteilungen in Kapitel 7, dass sie den Zusammenhang zwischen Histogramm und Boxplot verstehen! Nun zu den weiteren Streuungsparametern. Die Varianz \\(s^2\\) ist die mittlere (“durchschnittliche”) quadrierte Abweichung der Merkmalswerte \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) vom arithmetischen Mittel \\(\\bar x\\): \\[s^2=\\frac{\\sum_{i-1}^{n}\\left(x_i-\\bar x\\right)^2}{n-1}\\] Genau genommen ist das die korrigierte Varianz, wo durch \\(n-1\\) geteilt wird und nicht durch \\(n\\) wie man bei einer Mittelung erwarten würde. Das Teilen durch \\(n-1\\) garantiert eine optimale Schätzung der Varianz der Grundgesamtheit anhand der Stichprobe - mehr dazu in der schließenden Statistik. Der Nenner \\(n-1\\) wird Anzahl Freiheitsgrade genannt und bezeichnet die Anzahl der Werte in einer Stichprobe, die für die Berechnung des Parameters (hier Varianz) frei zur Verfügung stehen. Im Fall der Varianz ist ein Wert der Stichprobe bereits “belegt” – durch das arithmetische Mittel. Daher reduziert sich die Zahl der Elemente der Stichprobe, die in die Berechnung eingehen um eins. Die Standardabweichung \\(s\\) ist die Quadratwurzel der mittleren quadrierten Abweichung der Merkmalswerte \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) vom arithmetischen Mittel \\(\\bar x\\), d.h. die Quadratwurzel der Varianz: \\[s=\\sqrt{s^2}=\\sqrt{\\frac{\\sum_{i-1}^{n}\\left(x_i-\\bar x\\right)^2}{n-1}}\\] Die Standardabweichung besitzt die gleiche Einheit wie die Merkmalswerte und ist deshalb einfacher zu interpretieren als die Varianz. Sie drückt die Streuung der Merkmalswerte um den Mittelwert bzw. deren Abweichung vom Mittelwert in einer anschaulichen Größe aus. Je größer die Werte der Standardabweichung sind, desto mehr streuen die Daten. Der Variationskoeffizient \\(v\\) einer Häufigkeitsverteilung mit den Merkmalswerten \\(x_i\\quad\\left(i=1, 2, \\ldots, x_n\\right)\\) schließlich ist die Standardabweichung \\(s\\) im Verhältnis zum Mittelwert \\(\\bar x\\): \\[v=\\frac{s}{\\bar x}\\] Der Variationskoeffizient setzt die Streuung der Merkmalswerte in unmittelbare Relation zum arithmetischen Mittel. Dadurch werden unterschiedliche Verteilungen vergleichbar. Schauen wir uns die Streungsparameter für die Reisedaten mittels R an: # &quot;Entfernung&quot; in km # arithmethisches Mittel xbar &lt;- mean(dat$x/1000, na.rm = TRUE) xbar ## [1] 13.95896 # Varianz s2x &lt;- var(dat$x/1000, na.rm = TRUE) s2x ## [1] 68.74909 # Standardabweichung sx &lt;- sqrt(s2x) sx ## [1] 8.291507 sx &lt;- sd(dat$x/1000, na.rm = TRUE) sx ## [1] 8.291507 # Variationskoeffizient vx &lt;- sx / xbar vx ## [1] 0.5939919 # &quot;Reisezeit&quot; in min # arithmethisches Mittel tbar &lt;- mean(dat$t, na.rm = TRUE) tbar ## [1] 50.80612 # Varianz s2t &lt;- var(dat$t, na.rm = TRUE) s2t ## [1] 365.0445 # Standardabweichung st &lt;- sd(dat$t, na.rm = TRUE) st ## [1] 19.10614 # Variationskoeffizient vt &lt;- st / tbar vt ## [1] 0.3760598 Obwohl “Reisezeit” im Vergleich zu “Entfernung” eine viel größere Varianz hat ist der Variationskoeffizient kleiner, da Reisezeit auf einer größeren Skala gemessen wird. 4.2 Schiefe und Wölbung von Häufigkeitsverteilungen Lesen Sie dazu bitte Kapitel 3.2.5 von Zimmermann-Janschitz (2014). Die Schiefe \\(a_3\\) einer Häufigkeitsverteilung von Merkmalswerten \\(x_1, x_2, \\ldots, x_n\\) mit dem arithmetischen Mittel \\(\\bar x\\) und der Standardabweichung \\(s\\) bezeichnet die Abweichung der Verteilung der Merkmalswerte von der symmetrischen Form: \\[a_3=\\frac{\\sum_{i=1}^{n}\\left(x_i-\\bar x\\right)^3}{n\\cdot s^3}\\] Für eine symmetrische Verteilung gilt: \\[a_3=0\\quad \\bar x_{mod}=\\bar x_{med}=\\bar x\\] D.h. Modus, Median und Arithmetisches Mittel sind identisch. Für eine sogenannte rechtsschiefe (linkssteile) Verteilung gilt: \\[a_3&gt;0\\quad \\bar x_{mod}&lt;\\bar x_{med}&lt;\\bar x\\] Für eine linkschiefe (rechtssteile) Verteilung gilt: \\[a_3&lt;0\\quad \\bar x_{mod}&gt;\\bar x_{med}&gt;\\bar x\\] Wie wir an Histogramm und Boxplot der Entfernungsdaten bereits gesehen haben ist die Verteilung des Merkmals “Entfernung” rechtsschief: library(moments) # Schiefe skewness(dat$x/1000, na.rm = TRUE) ## [1] 1.430997 # Modus(=12.5) &lt; Median &lt; arithm. Mittelwert median(dat$x/1000, na.rm = TRUE) ## [1] 13.065 mean(dat$x/1000, na.rm = TRUE) ## [1] 13.95896 Die Verteilung des Merkmals “Reisezeit” dagegen ist weniger rechtsschief, annähernd symmetrisch, was man auch daran sieht, dass der Median und das aritmetische Mittel fast identisch sind: # Schiefe skewness(dat$t, na.rm = TRUE) ## [1] 0.4462817 # Modus(=45) &lt; Median &lt; arithm. Mittelwert median(dat$t, na.rm = TRUE) ## [1] 50 mean(dat$t, na.rm = TRUE) ## [1] 50.80612 Die Wölbung \\(a_4\\) einer Häufigkeitsverteilung von Merkmalswerten 𝑥\\(x_1, x_2, \\ldots, x_n\\) mit dem arithmetischen Mittel \\(\\bar x\\) und der Standardabweichung \\(s\\) bestimmt die Steilheit einer Verteilung: \\[a_4=\\frac{\\sum_{i=1}^{n}\\left(x_i-\\bar x\\right)^4}{n\\cdot s^4}-3\\] Die Subtraktion von “-3” dient der Standardisierung auf die sogenannte Normalverteilung, eine symmetrische, glockenförmige Verteilung (s. Zimmermann-Janschitz (2014), Kapitel 3.2.5). Mehr zur Normalverteilung in Kapitel 7. Für eine Normalverteilung gilt: \\[a_4=0\\] Für eine spitzere Verteilung als die Normalverteilung gilt: \\[a_4&gt;0\\] Für eine flachere Verteilung als die Normalverteilung gilt: \\[a_4&lt;0\\] Die Verteilungen der Merkmale unserer Reisedaten sind beide spitzer als die Normalverteilung, wobei “Entfernung” wegen der Rechtsschiefe garnicht mit der Normalverteilung vergleichbar ist: # Wölbung &quot;Entfernung&quot; kurtosis(dat$x/1000, na.rm = TRUE) - 3 ## [1] 3.86359 # Wölbung &quot;Reisezeit&quot; kurtosis(dat$t, na.rm = TRUE) - 3 ## [1] 0.9528005 Literatur "],
["korrelation.html", "Chapter 5 Korrelationsanalyse", " Chapter 5 Korrelationsanalyse "],
["wahrscheinlichkeit.html", "Chapter 6 Grundlagen der Wahrscheinlichkeitsrechnung", " Chapter 6 Grundlagen der Wahrscheinlichkeitsrechnung "],
["verteilungen.html", "Chapter 7 Verteilungen", " Chapter 7 Verteilungen "],
["schaetzen.html", "Chapter 8 Schaetzen von Verteilungsparametern", " Chapter 8 Schaetzen von Verteilungsparametern "],
["ttest.html", "Chapter 9 T-Test", " Chapter 9 T-Test "],
["ftest.html", "Chapter 10 F-Test", " Chapter 10 F-Test "],
["chi2test-kstest.html", "Chapter 11 Chi2- und Kolmogorow-Smirnow-Test", " Chapter 11 Chi2- und Kolmogorow-Smirnow-Test "],
["regression.html", "Chapter 12 Lineare Regression 12.1 Motivation 12.2 Definitionen", " Chapter 12 Lineare Regression 12.1 Motivation Kann man Ihre Reisezeit mit der Entfernung zu Ihrem Wohnort statistisch vorhersagen? (vgl. VL 5) Figure 12.1: Reisezeit in Abhängigkeit zur Entfernung. Korrelationskoeffizient nach Bravais-Pearson r\\(x,y\\)=0,86 Ziel: Eine Gerade durch die Punktwolke zu legen, die den Trend beschreibt, so dass der Abstand der Punkte von der Geraden minimal ist. Es geht um 2 Variablen (Merkmale): die abhängige Variable \\(y\\) (im Bsp. Reisezeit) die unabhängige Variable \\(x\\) (im Bsp. Entfernung) Die Variablen müssen metrisch skaliert sein. Wir wollen das generelle Verhalten von \\(y\\) mit \\(y\\) beschreiben. Eine Gerade ist das einfachste lineare Modell. 12.2 Definitionen Im Falle einer einzigen unabhängigen Variable ist die Gleichung des linearen Models wie folgt: \\[\\begin{equation} y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\tag{12.1} \\end{equation}\\] Mit \\(i\\) = 1,2,…,\\(n\\) \\(y_i\\) Wert der abhängigen Variable für Datenpunkt \\(i\\) \\(x_i\\) Wert der unabhängigen Variable für Datenpunkt \\(i\\) \\(\\beta_0\\) Achsenabschnitt der Geraden (ein Parameter) \\(\\beta_1\\) Steigung der Geraden (ein Parameter) \\(\\epsilon_i\\) Residuum (Fehler) für Datenpunkt \\(i\\) "],
["literatur.html", "Literatur", " Literatur "]
]
