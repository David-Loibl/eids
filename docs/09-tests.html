<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Kapitel 9 Statistische Tests | Einführung in die Statistik</title>
  <meta name="description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Kapitel 9 Statistische Tests | Einführung in die Statistik" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  <meta name="github-repo" content="krueger-t/eids" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kapitel 9 Statistische Tests | Einführung in die Statistik" />
  
  <meta name="twitter:description" content="This is the script of the course ‘Einführung in die Statistik’ (in German) run at the Geography Department of Humboldt-Universität zu Berlin." />
  

<meta name="author" content="Tobias Krueger" />


<meta name="date" content="2021-01-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="08-schaetzen.html"/>
<link rel="next" href="10-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Einführung in die Statistik</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="part"><span><b>Grundlagen</b></span></li>
<li class="chapter" data-level="1" data-path="01-einfuehrung.html"><a href="01-einfuehrung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a></li>
<li class="chapter" data-level="2" data-path="02-begriffe.html"><a href="02-begriffe.html"><i class="fa fa-check"></i><b>2</b> Grundbegriffe und Datenerhebung</a></li>
<li class="part"><span><b>Deskriptive Statistik</b></span></li>
<li class="chapter" data-level="3" data-path="03-haeufigkeit.html"><a href="03-haeufigkeit.html"><i class="fa fa-check"></i><b>3</b> Häufigkeiten und Lageparameter</a></li>
<li class="chapter" data-level="4" data-path="04-streuung.html"><a href="04-streuung.html"><i class="fa fa-check"></i><b>4</b> Streuungsparameter, Schiefe und Wölbung</a></li>
<li class="chapter" data-level="5" data-path="05-korrelation.html"><a href="05-korrelation.html"><i class="fa fa-check"></i><b>5</b> Korrelationsanalyse</a></li>
<li class="part"><span><b>Wahrscheinlichkeitstheorie</b></span></li>
<li class="chapter" data-level="6" data-path="06-wahrscheinlichkeit.html"><a href="06-wahrscheinlichkeit.html"><i class="fa fa-check"></i><b>6</b> Grundlagen der Wahrscheinlichkeitsrechnung</a></li>
<li class="chapter" data-level="7" data-path="07-verteilungen.html"><a href="07-verteilungen.html"><i class="fa fa-check"></i><b>7</b> Verteilungen</a></li>
<li class="part"><span><b>Induktive Statistik</b></span></li>
<li class="chapter" data-level="8" data-path="08-schaetzen.html"><a href="08-schaetzen.html"><i class="fa fa-check"></i><b>8</b> Schätzen von Verteilungsparametern</a></li>
<li class="chapter" data-level="9" data-path="09-tests.html"><a href="09-tests.html"><i class="fa fa-check"></i><b>9</b> Statistische Tests</a></li>
<li class="chapter" data-level="10" data-path="10-regression.html"><a href="10-regression.html"><i class="fa fa-check"></i><b>10</b> Lineare Regression</a></li>
<li class="appendix"><span><b>Referenzen</b></span></li>
<li class="chapter" data-level="" data-path="11-refs.html"><a href="11-refs.html"><i class="fa fa-check"></i>Literatur</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Einführung in die Statistik</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tests" class="section level1">
<h1><span class="header-section-number">Kapitel 9</span> Statistische Tests</h1>
<p>Wie wir in Kapitel <a href="08-schaetzen.html#schaetzen">8</a> gelernt haben geht es in der schließenden Statistik um die Verdichtung der Informationen in einer Stichprobe in Form von Stichprobenfunktionen, mit denen wir <em>bestimmte Parameter der Grundgesamtheit schätzen</em> (vgl. <span class="citation">Mittag (<a href="#ref-mittag2016" role="doc-biblioref">2016</a>)</span>, Abb. 14.1, S. 212). Waehrend es sich im Fall von Verteilungsparametern bei den Stichprobenfunktionen v.a. um den Mittelwert und die Standardabweichung handelt, sind die Stichprobenfunktionen im Fall von statistischen Tests sogenannte <strong>Teststatistiken</strong>, die die Informationen in der Stichprobe verdichten.</p>
<p>Wir werden das vorliegende Kapitel ueber die naechsten drei Wochen lesen. Dabei werden wir anhand der folgenden neun Beispiele vier verschiedene Tests kennenlernen:</p>
<ul>
<li><strong>Beispiel 1</strong>: Laut <a href="https://www.personalwirtschaft.de/der-job-hr/arbeitswelt/artikel/pendelstrecken-werden-immer-laenger.html">dieser Umfrage</a> hält jeder zweite Berufspendler eine durchschnittliche Fahrtzeit von bis zu 60 min pro Strecke für akzeptabel. Im Wintersemester 2019/20 haben wir die Anreisezeiten der Studierenden dieses Kurses abgefragt.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Ein Histogramm dieser Stichprobe sehen Sie in Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>. Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>kleiner</em> als der Vergleichswert <span class="math inline">\(\mu_0=60\)</span> aus der Studie? Beziehungsweise, ist der <em>Unterschied statistisch signifikant</em>, wenn wir die Streuung der Stichprobe berücksichtigen? Die Frage “kleiner als” wenn es um einen Mittelwert geht beantwortet der sogenannte <strong>linksseitige Einstichproben-t-Test</strong> (Kapitel <a href="09-tests.html#ttest1">9.2.1</a>).</li>
<li><strong>Beispiel 2</strong>: Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>ungleich</em> dem Vergleichswert <span class="math inline">\(\mu_0=60\)</span> aus der Studie? Wenn wir die Frage so formulieren brauchen wir einen sogenannten <strong>zweiseitigen Einstichproben-t-Test</strong> (Kapitel <a href="09-tests.html#ttest1">9.2.1</a>).</li>
<li><strong>Beispiel 3</strong>: Laut <a href="https://www.personalwirtschaft.de/der-job-hr/arbeitswelt/artikel/pendelstrecken-werden-immer-laenger.html">derselben Umfrage</a> nehmen 21% der Pendler eine Fahrtzeit zwischen 30 und 45 min in Kauf. Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>groesser</em> als der Vergleichswert <span class="math inline">\(\mu_0=45\)</span> aus der Studie? Beziehungsweise, ist der <em>Unterschied statistisch signifikant</em>, wenn wir die Streuung der Stichprobe berücksichtigen? Die Frage “groesser als” beantwortet der <strong>rechtsseitige Einstichproben-t-Test</strong> (Kapitel <a href="09-tests.html#ttest1">9.2.1</a>).<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></li>
<li><strong>Beispiel 4</strong>: Die Stichprobe wurde zufällig geteilt (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>). Sind die mit den neuen Stichprobenmitteln <span class="math inline">\(\bar x_1=50.4\)</span> und <span class="math inline">\(\bar x_2=51.2\)</span> geschätzten Mittelwerte <span class="math inline">\(\mu_1\)</span> und <span class="math inline">\(\mu_2\)</span> ungleich? Beziehungsweise, können wir statistisch nachvollziehen, dass die beiden Stichproben Grundgesamtheiten mit dem selben Mittelwert entstammen? Diese Frage beantwortet der sogenannte <strong>Zweistichproben-t-Test (zweiseitig)</strong> (Kapitel <a href="09-tests.html#ttest2">9.2.2</a>).</li>
<li><strong>Beispiel 5</strong> <span class="citation">(Dormann <a href="#ref-dormann2013" role="doc-biblioref">2013</a>)</span>: Auf den Nord- und Suedseiten einer Stichprobe von Baeumen wurde jeweils die Anzahl Moosarten bestimmt (Abbildung <a href="09-tests.html#fig:fmoose">9.3</a>). Ist die Anzahl Moosarten auf der Nord- und Südseite <em>derselben</em> Bäume unterschiedlich? Dafuer brauchen wir den <strong>gepaarten Zweistichproben-t-Test (zweiseitig)</strong> (Kapitel <a href="09-tests.html#ttest2gepaart">9.2.3</a>).</li>
<li><strong>Beispiel 6</strong>: Zurueck zu den beiden neuen Stichproben aus Beispiel 4 (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>). Ist die Varianz <span class="math inline">\(\sigma_2^2\)</span> (gegeben <span class="math inline">\(s_2^2=384\)</span>) groesser als die Varianz <span class="math inline">\(\sigma_1^2\)</span> (gegeben <span class="math inline">\(s_1^2=352\)</span>)? Beziehungsweise, können wir statistisch nachvollziehen, dass die beiden Stichproben Grundgesamtheiten mit derselben Varianz entstammen? Diese Frage beantwortet der sogenannte <strong>F-Test (rechtsseitig)</strong> (Kapitel <a href="09-tests.html#ftest">9.5</a>).</li>
<li><strong>Beispiel 7</strong>: Entstammt die Stichprobe der Reisezeit (Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>) einer normalverteilten Grundgesamtheit? Die Parameter dieser Normalverteilung werden anhand der Stichprobe geschätzt. Diese Frage beantwortet der sogenannte <strong>Einstichproben-Kolmogorow-Smirnow-Test</strong> (Kapitel <a href="09-tests.html#kstest">9.6</a>).</li>
<li><strong>Beispiel 8</strong>: Entstammen die beiden Teilstichproben der Reisezeit (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>) einer gemeinsamen Verteilung? Beziehungsweise, koennen wir das statistisch nachvollziehen? Dafuer brauchen wir den <strong>Zweistichproben-Kolmogorow-Smirnow-Test</strong> (Kapitel <a href="09-tests.html#kstest">9.6</a>).</li>
<li><strong>Beispiel 9</strong>: Zurueck zum Volksentscheid Tegel aus Kapitel <a href="05-korrelation.html#korrelation">5</a>. Gibt es einen Zusammenhang zwischen “Bezirk” und “Votum” beim Volksentscheid Tegel? Beziehungsweise, ist der geringe Zusammenhang, den wir bereits festgestellt haben, statistisch signifikant? Diese Frage beantwortet der sogenannte <strong>Chi-Quadrat-Test</strong> (Kapitel <a href="09-tests.html#chi2test">9.7</a>).</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:freisezeit"></span>
<img src="eids_files/figure-html/freisezeit-1.png" alt="Histogramm des Merkmals &quot;Anreisezeit&quot; der Reisedaten aus dem Wintersemester 2019/20. Die vertikale Linie markiert den Mittelwert von 50.8 min." width="80%" />
<p class="caption">
Abbildung 9.1: Histogramm des Merkmals “Anreisezeit” der Reisedaten aus dem Wintersemester 2019/20. Die vertikale Linie markiert den Mittelwert von 50.8 min.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:freisezeit2"></span>
<img src="eids_files/figure-html/freisezeit2-1.png" alt="Histogramme des Merkmals &quot;Anreisezeit&quot; der Reisedaten aus dem Wintersemester 2019/20. Die Stichprobe wurde zufaellig geteilt. Die vertikalen Linien markieren die Mittelwerte $\bar x_1=50.4$ (links) und $\bar x_2=51.2$ (rechts). Die Varianzen sind $s_1^2=352$ und $s_2^2=384$." width="50%" /><img src="eids_files/figure-html/freisezeit2-2.png" alt="Histogramme des Merkmals &quot;Anreisezeit&quot; der Reisedaten aus dem Wintersemester 2019/20. Die Stichprobe wurde zufaellig geteilt. Die vertikalen Linien markieren die Mittelwerte $\bar x_1=50.4$ (links) und $\bar x_2=51.2$ (rechts). Die Varianzen sind $s_1^2=352$ und $s_2^2=384$." width="50%" />
<p class="caption">
Abbildung 9.2: Histogramme des Merkmals “Anreisezeit” der Reisedaten aus dem Wintersemester 2019/20. Die Stichprobe wurde zufaellig geteilt. Die vertikalen Linien markieren die Mittelwerte <span class="math inline">\(\bar x_1=50.4\)</span> (links) und <span class="math inline">\(\bar x_2=51.2\)</span> (rechts). Die Varianzen sind <span class="math inline">\(s_1^2=352\)</span> und <span class="math inline">\(s_2^2=384\)</span>.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fmoose"></span>
<img src="eids_files/figure-html/fmoose-1.png" alt="Verteilung der Anzahl Moosarten auf der Suedseite (links) und Nordseite (rechts) derselben Baeume. Daten aus: @dormann2013." width="50%" /><img src="eids_files/figure-html/fmoose-2.png" alt="Verteilung der Anzahl Moosarten auf der Suedseite (links) und Nordseite (rechts) derselben Baeume. Daten aus: @dormann2013." width="50%" />
<p class="caption">
Abbildung 9.3: Verteilung der Anzahl Moosarten auf der Suedseite (links) und Nordseite (rechts) derselben Baeume. Daten aus: <span class="citation">Dormann (<a href="#ref-dormann2013" role="doc-biblioref">2013</a>)</span>.
</p>
</div>
<div id="grundprinzipien-statistischer-tests" class="section level2">
<h2><span class="header-section-number">9.1</span> Grundprinzipien statistischer Tests</h2>
<p>Die folgenden Prinzipien liegen allen statistischen Tests zugrunde, wobei wir vieles am Beispiel des t-Tests demonstrieren, der dann in Kapitel <a href="09-tests.html#ttest">9.2</a> vollstaendig behandelt wird.</p>
<div id="nullhypothese-und-alternativhypothese" class="section level3">
<h3><span class="header-section-number">9.1.1</span> Nullhypothese und Alternativhypothese</h3>
<p>Das Formulieren von Hypothesen ist die formale Vorgehensweise, Fragestellungen wie die oben genannten Beispiele statistisch zu übersetzen.</p>
<blockquote>
<p>Bsp. 3: Ist <span class="math inline">\(\mu\)</span> (gegeben <span class="math inline">\(\bar x=50.8\)</span>) größer als <span class="math inline">\(\mu_0=45\)</span>?</p>
</blockquote>
<p>Jeder statistische Test verlangt eine bestimmte <strong>Nullhypothese</strong> <span class="math inline">\(H_0\)</span>.</p>
<blockquote>
<p>Bsp. 3: <span class="math inline">\(H_0: \mu\leq\mu_0\)</span></p>
</blockquote>
<p>Diese wird getestet. Die <strong>Alternativhypothese</strong> <span class="math inline">\(H_1\)</span> ist aber die, die sich zunächst aus den Zahlenwerten ergibt.</p>
<blockquote>
<p>Bsp. 3: <span class="math inline">\(H_1: \mu&gt;\mu_0\)</span></p>
</blockquote>
<p>Hypothesen können nur abgelehnt (falsifiziert) werden. Das Annehmen von Hypothesen gilt nur <em>bis auf weiteres</em>.</p>
</div>
<div id="zweiseitig-und-einseitig" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Zweiseitig und einseitig</h3>
<p>Wir unterscheiden zweiseitige und einseitige Tests. Bei <strong>zweiseitigen</strong> Tests wird auf <em>ungleich/gleich</em> getestet.</p>
<blockquote>
<p>Bsp. 2: Ist <span class="math inline">\(\mu\)</span> (gegeben <span class="math inline">\(\bar x=50.8\)</span>) ungleich <span class="math inline">\(\mu_0=60\)</span>?</p>
</blockquote>
<p>Bei <strong>einseitigen</strong> Tests wird auf <em>kleiner/nicht kleiner</em> oder <em>größer/nicht größer</em> getestet.</p>
<blockquote>
<p>Bsp. 1: Ist <span class="math inline">\(\mu\)</span> (gegeben <span class="math inline">\(\bar x=50.8\)</span>) kleiner als <span class="math inline">\(\mu_0=60\)</span>?</p>
</blockquote>
<p>Ein einseitiger Test ist in der Regel aussagekräftiger. Die Ergebnisse beider Tests lassen sich aber einfach ineinander überführen - wie wir noch sehen werden.</p>
</div>
<div id="die-teststatistik" class="section level3">
<h3><span class="header-section-number">9.1.3</span> Die Teststatistik</h3>
<p>Jeder Test hat eine bestimmte <strong>Teststatistik</strong> (Prüfwert) von der wir wissen, wie sie verteilt ist (unter bestimmten Annahmen), <em>falls die Nullhypothese wahr ist</em>. Die Teststatistik eines Einstichproben-t-Tests beispielsweise ist:
<span class="math display" id="eq:ts">\[\begin{equation}
t_s=\frac{\hat\mu-\mu_0}{s_{\hat\mu}}\sim t_{n-1}
\tag{9.1}
\end{equation}\]</span></p>
<p><span class="math inline">\(\hat\mu\)</span> ist der Mittelwertschaetzer; in Bsp. 1 <span class="math inline">\(\hat\mu=\bar x=50.8\)</span>. <span class="math inline">\(\mu_0\)</span> ist der Wert, mit dem wir den Schätzer vergleichen; in Bsp. 1 <span class="math inline">\(\mu_0=60\)</span>. <span class="math inline">\(s_{\hat\mu}\)</span> ist der Standardfehler des Mittelwertschaetzers. Ist die Grundgesamtheit normalverteilt, dann ist der so standardisierte Schätzer des Mittelwertes (die Teststatistik <span class="math inline">\(t_s\)</span>) bei wiederholtem Stichprobenziehen t-verteilt mit <span class="math inline">\(n-1\)</span> Freiheitsgraden (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>).<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="was-genau-getestet-wird" class="section level3">
<h3><span class="header-section-number">9.1.4</span> Was genau getestet wird</h3>
<p>Wenn die Teststatistik nahe dem Zentrum der Verteilung ist, die unter der Nullhypothese zu erwarten ist, d.h. in einem Bereich hoher Wahrscheinlichkeit, dann lehnen wir die Nullhypothese <em>nicht</em> ab. In Abbildung <a href="09-tests.html#fig:testprinzip">9.4</a> ist das fuer die Teststatistik <span class="math inline">\(t_s\)</span> in blau und die t-Verteilung dargestellt. Im Bsp. 2 würden wir in so einem Fall bis auf weiteres schließen, dass <span class="math inline">\(\mu\)</span> (gegeben <span class="math inline">\(\bar x=50.8\)</span>) gleich <span class="math inline">\(\mu_0=60\)</span> ist.</p>
<p>Ist die Teststatistik dagegen in den Extremen der Verteilung, d.h. in einem Bereich geringer Wahrscheinlichkeit, dann lehnen wir die Nullhypothese ab. In Abbildung <a href="09-tests.html#fig:testprinzip">9.4</a> ist das mit den roten Pfeilen verdeutlicht. Im Bsp. 2 würden wir in so einem Fall schließen, dass <span class="math inline">\(\mu\)</span> (gegeben <span class="math inline">\(\bar x=50.8\)</span>) ungleich <span class="math inline">\(\mu_0=60\)</span> ist. Das ist in dem Beispiel tatsaechlich das Ergebnis - wie wir noch sehen werden.</p>
<div class="figure" style="text-align: center"><span id="fig:testprinzip"></span>
<img src="eids_files/figure-html/testprinzip-1.png" alt="Grundprinzip des statistischen Testens, hier dargestellt fuer einen konstruierten t-Test: Verteilungsfunktion der t-Verteilung mit 97 Freiheitsgraden, mit Teststatistik $t_s$ (blau) im Zentrum der Verteilung, d.h. im Bereich hoher Wahrscheinlichkeit unter der Nullhypothese. Wir lehnen die Nullhypothese _nicht_ ab. Waere die Teststatistik dagegen in den Extremen der Verteilung (mit roten Pfeilen verdeutlicht), waere sie im Bereich geringer Wahrscheinlichkeit unter der Nullhypothese. In dem Fall lehnen wir die Nulhypothese ab." width="80%" />
<p class="caption">
Abbildung 9.4: Grundprinzip des statistischen Testens, hier dargestellt fuer einen konstruierten t-Test: Verteilungsfunktion der t-Verteilung mit 97 Freiheitsgraden, mit Teststatistik <span class="math inline">\(t_s\)</span> (blau) im Zentrum der Verteilung, d.h. im Bereich hoher Wahrscheinlichkeit unter der Nullhypothese. Wir lehnen die Nullhypothese <em>nicht</em> ab. Waere die Teststatistik dagegen in den Extremen der Verteilung (mit roten Pfeilen verdeutlicht), waere sie im Bereich geringer Wahrscheinlichkeit unter der Nullhypothese. In dem Fall lehnen wir die Nulhypothese ab.
</p>
</div>
<blockquote>
<p>Beachte: Bei der zweiseitigen Version des Tests schauen wir auf beiden Seiten der Verteilung (beide Extreme), waehrend wir bei dem linksseitigen Test nur auf die linke und bei dem rechtsseitigen Test nur auf die rechte Seite schauen. Auf der linken Seite von Abbildung <a href="09-tests.html#fig:testprinzip">9.4</a> befinden wir uns mit der Teststatistik <span class="math inline">\(t_s\)</span> wenn <span class="math inline">\(\hat\mu&lt;\mu_0\)</span>, d.h. wir testen kleiner/nicht kleiner. Auf der rechten Seite befinden wir uns wenn <span class="math inline">\(\hat\mu&gt;\mu_0\)</span>, d.h. wir testen groesser/nicht groesser.</p>
</blockquote>
</div>
</div>
<div id="ttest" class="section level2">
<h2><span class="header-section-number">9.2</span> t-Test (Vergleich von Mittelwerten)</h2>
<p>Jetzt haben wir schon viel ueber den t-Test gehoert; er ist dazu da, <em>Mittelwerte zu vergleichen</em>. Wenn wir den Mittelwert einer Stichprobe gegen einen Vergleichswert testen dann ist das der <strong>Einstichproben-t-Test</strong>. Wenn wir die Mittelwerte zweier Stichproben vergleichen dann ist das der <strong>Zweistichproben-t-Test</strong>. Wenn die beiden Stichproben <em>gepaart</em> sind, d.h. wenn die Merkmalswerte jeweils fuer <em>die selbe statistische Einheit</em> erhoben wurden, dann spricht man vom <strong>gepaarten Zweistichproben-t-Test</strong>. Die Teststatistik ist in allen diesen Faellen aehnlich. Schauen wir uns nun die Varianten des t-Tests anhand der Beispiele an.</p>
<div id="ttest1" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Einstichproben-t-Test</h3>
<blockquote>
<p>Bsp. 1 (Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>): Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>kleiner</em> als der Vergleichswert <span class="math inline">\(\mu_0=60\)</span>? Beziehungsweise, ist der <em>Unterschied statistisch signifikant</em>, wenn wir die Streuung der Stichprobe berücksichtigen?</p>
</blockquote>
<p>Die Nullhypothese ist in diesem Fall, dass der Mittelwert größer oder gleich dem Vergleichswert ist:
<span class="math display">\[H_0:\mu\geq\mu_0\]</span>
Die Alternativhypothese ist, dass der Mittelwert <em>kleiner</em> als der Vergleichswert ist:
<span class="math display">\[H_1:\mu&lt;\mu_0\]</span></p>
<p>Das ist die Formulierung des <strong>linksseitigen</strong> Testes. Die Teststatistik (Formel <a href="09-tests.html#eq:ts">(9.1)</a>) rechnen wir anhand der Stichprobe wie folgt aus (vgl. Kapitel <a href="08-schaetzen.html#schaetzen">8</a>):
<span class="math display">\[t_s=\frac{\hat\mu-\mu_0}{s_{\hat\mu}}\sim t_{n-1}\]</span>
<span class="math display">\[t_s=\frac{\bar x-\mu_0}{s_{\bar x}}\sim t_{n-1}\]</span>
<span class="math display">\[t_s=\frac{\bar x-\mu_0}{s}\cdot\sqrt{n}\sim t_{n-1}\]</span></p>
<p>Setzen wir die Zahlenwerte aus der Stichprobe ein (“reisedat19$t” enthaelt die Merkmalswerte fuer “Anreisezeit” aus dem Wintersemester 2019/20):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="09-tests.html#cb1-1"></a><span class="co"># Mittelwert</span></span>
<span id="cb1-2"><a href="09-tests.html#cb1-2"></a><span class="co"># na.rm=TRUE ignoriert NAs</span></span>
<span id="cb1-3"><a href="09-tests.html#cb1-3"></a>xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(reisedat19<span class="op">$</span>t, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</span>
<span id="cb1-4"><a href="09-tests.html#cb1-4"></a>xbar</span></code></pre></div>
<pre><code>## [1] 50.80612</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="09-tests.html#cb3-1"></a><span class="co"># Vergleichswert</span></span>
<span id="cb3-2"><a href="09-tests.html#cb3-2"></a>mu0 &lt;-<span class="st"> </span><span class="dv">60</span></span>
<span id="cb3-3"><a href="09-tests.html#cb3-3"></a><span class="co"># Standardabweichung</span></span>
<span id="cb3-4"><a href="09-tests.html#cb3-4"></a><span class="co"># na.rm=TRUE ignoriert NAs</span></span>
<span id="cb3-5"><a href="09-tests.html#cb3-5"></a>s &lt;-<span class="st"> </span><span class="kw">sd</span>(reisedat19<span class="op">$</span>t, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</span>
<span id="cb3-6"><a href="09-tests.html#cb3-6"></a>s</span></code></pre></div>
<pre><code>## [1] 19.10614</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="09-tests.html#cb5-1"></a><span class="co"># Stichprobenumfang</span></span>
<span id="cb5-2"><a href="09-tests.html#cb5-2"></a><span class="co"># !is.na(reisedat19$t) verweist auf die Werte, die nicht NA sind</span></span>
<span id="cb5-3"><a href="09-tests.html#cb5-3"></a>n &lt;-<span class="st"> </span><span class="kw">length</span>(reisedat19<span class="op">$</span>t[<span class="op">!</span><span class="kw">is.na</span>(reisedat19<span class="op">$</span>t)])</span>
<span id="cb5-4"><a href="09-tests.html#cb5-4"></a>n</span></code></pre></div>
<pre><code>## [1] 98</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="09-tests.html#cb7-1"></a><span class="co"># Teststatistik</span></span>
<span id="cb7-2"><a href="09-tests.html#cb7-2"></a>ts &lt;-<span class="st"> </span>(xbar <span class="op">-</span><span class="st"> </span>mu0)<span class="op">/</span>s<span class="op">*</span><span class="kw">sqrt</span>(n)</span>
<span id="cb7-3"><a href="09-tests.html#cb7-3"></a>ts</span></code></pre></div>
<pre><code>## [1] -4.763639</code></pre>
<p>Dieser Wert der Teststatistik ist in den Extremen der t-Verteilung, die unter der Nullhypothese zu erwarten ist:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="09-tests.html#cb9-1"></a><span class="kw">plot</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), <span class="kw">pt</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), n<span class="dv">-1</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,</span>
<span id="cb9-2"><a href="09-tests.html#cb9-2"></a>     <span class="dt">xlab=</span><span class="st">&#39;Z=t_s&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Verteilungsfunktion&#39;</span>)</span>
<span id="cb9-3"><a href="09-tests.html#cb9-3"></a><span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)<span class="op">*</span>ts, <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pt</span>(ts, n<span class="dv">-1</span>)), <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb9-4"><a href="09-tests.html#cb9-4"></a><span class="kw">text</span>(ts,<span class="op">-</span><span class="fl">0.2</span>,<span class="st">&quot;t_s&quot;</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">xpd=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Wie extrem der Wert der Teststatistik ist (wie unwahrscheinlich er unter der Nullhypothese ist) misst der sogenannte p-Wert. Der <strong>p-Wert</strong> ist die Wahrscheinlichkeit, unter Annahme der Nullhypothese, durch Zufall einen extremeren Wert als den der Teststatistik zu erhalten. In Formelsprache:
<span class="math display">\[\Pr\left(Z&lt;t_s\right)=F_t\left(t_s\right)\]</span>
Die Wahrscheinlichkeit eines kleineren Wertes als den der vorliegenden Teststatistik ist gleich der Verteilungsfunktion an der Stelle der Teststatistik (vgl. Kapitel <a href="07-verteilungen.html#verteilungen">7</a>). Mit Zahlenwerten:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="09-tests.html#cb10-1"></a><span class="kw">pt</span>(ts, n<span class="dv">-1</span>)</span></code></pre></div>
<pre><code>## [1] 3.331443e-06</code></pre>
<p>Der p-Wert ist sehr klein, d.h. es ist sehr unwahrscheinlich, dass dieser Wert der Teststatisk durch Zufall zustande kam falls die Nullhypothese wahr ist, d.h. wir sollten die Nullhypothese ablehnen. In der Praxis entscheiden wir das auf Basis eines sogenannten <strong>Signifikanzniveaus</strong> von 0.01: Ist der p-Wert kleiner oder gleich 0.01 lehnen wir Nullhypothese ab. Ist der p-Wert groesser als 0.01 behalten wir die Nullhypothese (bis auf weiteres) bei. Das Signifikanzniveau von 0.01 ist reine Konvention! Tatsaechlich gab es dazu kuerzlich eine <a href="https://doi.org/10.1038/d41586-019-00874-8">Debatte unter Statistikern</a>. <em>R</em> gibt Signifikanz zu mehreren Niveaus an. Grundsaetzlich ist immer der p-Wert anzugeben; dann kann jede Person ihr eigenes Signifikanzniveau ansetzen.</p>
<p>Fuer unser Beispiel 1 schliessen wir also: Der Unterschied zwischen dem mit dem Stichprobenmittel <span class="math inline">\(\bar x\)</span> geschätzten Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit und dem Vergleichswert <span class="math inline">\(\mu_0=60\)</span> ist <em>statistisch signifikant</em>.</p>
<p>Wir koennen die Fragestellung aber auch etwas schwaecher formulieren, als <strong>zweiseitiges</strong> Testproblem:</p>
<blockquote>
<p>Bsp. 2 (Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>): Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>ungleich</em> dem Vergleichswert $_0=60?</p>
</blockquote>
<p>Die Nullhypothese ist in diesem Fall, dass der Mittelwert gleich dem Vergleichswert ist:
<span class="math display">\[H_0:\mu=\mu_0\]</span>
Die Alternativhypothese ist, dass die beiden Wert <em>nicht</em> gleich sind:
<span class="math display">\[H_1:\mu\ne\mu_0\]</span></p>
<p>Die Teststatistik ist die gleiche wie im linksseitigen Fall, nur dass wir jetzt auf beide Extreme der t-Verteilung schauen, die unter der Nullhypothese zu erwarten ist:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="09-tests.html#cb12-1"></a><span class="kw">plot</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), <span class="kw">pt</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), n<span class="dv">-1</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,</span>
<span id="cb12-2"><a href="09-tests.html#cb12-2"></a>     <span class="dt">xlab=</span><span class="st">&#39;Z=t_s&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Verteilungsfunktion&#39;</span>)</span>
<span id="cb12-3"><a href="09-tests.html#cb12-3"></a><span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)<span class="op">*</span>ts, <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pt</span>(ts, n<span class="dv">-1</span>)), <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb12-4"><a href="09-tests.html#cb12-4"></a><span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)<span class="op">*</span>(<span class="op">-</span>ts), <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pt</span>(<span class="op">-</span>ts, n<span class="dv">-1</span>)), <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb12-5"><a href="09-tests.html#cb12-5"></a><span class="kw">text</span>(ts,<span class="op">-</span><span class="fl">0.2</span>,<span class="st">&quot;t_s&quot;</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">xpd=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Wir spiegeln also den Wert der Teststatistik an Null, und der p-Wert ist jetzt die Wahrscheinlichkeit eines Wertes der Teststatistik jenseits dieser <em>beiden</em> Grenzen:
<span class="math display">\[\Pr\left(Z&lt;t_s\right)+\Pr\left(Z&gt;-t_s\right)=2\cdot\Pr\left(Z&gt;\left|t_s\right|\right)=2\cdot \left(1-F_t\left(\left|t_s\right|\right)\right)\]</span>
Die Wahrscheinlichkeit eines extremeren Wertes als den der vorliegenden Teststatistik (auf beiden Seiten) ist zweimal die Wahrscheinlichkeit eines groesseren Wertes als den Absolutwert <span class="math inline">\(\left|t_s\right|\)</span> der vorliegenden Teststatistik - wegen der Symmetrie der t-Verteilung um Null. Die Wahrscheinlichkeit eines groesseren Wertes ist Eins minus die Verteilungsfunktion an der entsprechenden Stelle (vgl. Kapitel <a href="07-verteilungen.html#verteilungen">7</a>). Mit Zahlenwerten:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="09-tests.html#cb13-1"></a><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pt</span>(<span class="kw">abs</span>(ts),n<span class="dv">-1</span>))</span></code></pre></div>
<pre><code>## [1] 6.662886e-06</code></pre>
<p>Wie wir sehen ist der p-Wert des zweiseitigen Tests genau zweimal der p-Wert des einseitigen Tests. D.h. wenn der zweiseitige Test signifikant ist, dann ist auch der einseitige Test signifikant. In der Praxis wird oft ein zweiseitiger Test durchgefuehrt und dann fuer die einseitige Variante, die sich aus den Zahlenwerten ergibt (hier Bsp. 1), der p-Wert halbiert.</p>
<p>Fuer Beispiel 2 schliessen wir jedenfalls: Es kann ausgeschlossen werden, dass der mit dem Stichprobenmittel <span class="math inline">\(\bar x\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit gleich dem Vergleichswert <span class="math inline">\(\mu_0=60\)</span> ist. Der zweiseitige Test ist wie gesagt ein schwaecherer Test als der einseitige, den wir bereits in Bsp. 1 durchgefuehrt haben. In der Praxis wuerde man die Tests nicht so hintereinander schalten, sondern umgekehrt.</p>
<p>Es fehlt noch der <strong>rechtsseitige</strong> Test, fuer den wir eine Fragestellung wie folgt konstruiert haben:</p>
<blockquote>
<p>Bsp. 3 (Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>): Ist der mit dem Stichprobenmittel <span class="math inline">\(\bar x=50.8\)</span> geschätzte Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit <em>groesser</em> als der Vergleichswert <span class="math inline">\(\mu_0=45\)</span>? Beziehungsweise, ist der <em>Unterschied statistisch signifikant</em>, wenn wir die Streuung der Stichprobe berücksichtigen?</p>
</blockquote>
<p>Die Nullhypothese ist in diesem Fall, dass der Mittelwert kleiner oder gleich dem Vergleichswert ist:
<span class="math display">\[H_0:\mu\leq\mu_0\]</span>
Die Alternativhypothese ist, dass der Mittelwert <em>größer</em> als der Vergleichswert ist:
<span class="math display">\[H_1:\mu&gt;\mu_0\]</span></p>
<p>Die Formel der Teststatistik ist die gleiche wie im links- und zeiseitigen Fall, nur dass wir jetzt gemaess der Fragestellung <span class="math inline">\(\mu_0=45\)</span> einsetzen:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="09-tests.html#cb15-1"></a>ts &lt;-<span class="st"> </span>(xbar <span class="op">-</span><span class="st"> </span><span class="dv">45</span>)<span class="op">/</span>s<span class="op">*</span><span class="kw">sqrt</span>(n)</span>
<span id="cb15-2"><a href="09-tests.html#cb15-2"></a>ts</span></code></pre></div>
<pre><code>## [1] 3.008336</code></pre>
<p>Der Wert der Teststatistik ist jetzt positiv, da <span class="math inline">\(\bar x\)</span> groesser ist als <span class="math inline">\(\mu_0\)</span>. Er ist ebenfalls in den Extremen der t-Verteilung, die unter der Nullhypothese zu erwarten ist:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="09-tests.html#cb17-1"></a><span class="kw">plot</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), <span class="kw">pt</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.01</span>), n<span class="dv">-1</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,</span>
<span id="cb17-2"><a href="09-tests.html#cb17-2"></a>     <span class="dt">xlab=</span><span class="st">&#39;Z=t_s&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Verteilungsfunktion&#39;</span>)</span>
<span id="cb17-3"><a href="09-tests.html#cb17-3"></a><span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)<span class="op">*</span>ts, <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pt</span>(ts, n<span class="dv">-1</span>)), <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb17-4"><a href="09-tests.html#cb17-4"></a><span class="kw">text</span>(ts,<span class="op">-</span><span class="fl">0.2</span>,<span class="st">&quot;t_s&quot;</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">xpd=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="eids_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Der p-Wert im rechtseitigen Fall ist:
<span class="math display">\[\Pr\left(Z&gt;t_s\right)=1-F_t\left(t_s\right)\]</span>
Die Wahrscheinlichkeit eines groesseren Wertes als den der vorliegenden Teststatistik ist Eins minus die Verteilungsfunktion an der Stelle der Teststatistik (vgl. Kapitel <a href="07-verteilungen.html#verteilungen">7</a>). Mit Zahlenwerten:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="09-tests.html#cb18-1"></a><span class="dv">1</span><span class="op">-</span><span class="kw">pt</span>(ts, n<span class="dv">-1</span>)</span></code></pre></div>
<pre><code>## [1] 0.001673177</code></pre>
<p>Der p-Wert ist ebenfalls kleiner als das konventionelle <strong>Signifikanzniveau</strong> von 0.01, d.h. wir lehnen die Nullhypothese ab und schliessen fuer Beispiel 3: Der Unterschied zwischen dem mit dem Stichprobenmittel <span class="math inline">\(\bar x\)</span> geschätzten Mittelwert <span class="math inline">\(\mu\)</span> der Grundgesamtheit und dem Vergleichswert <span class="math inline">\(\mu_0=45\)</span> ist <em>statistisch signifikant</em>.</p>
</div>
<div id="ttest2" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Zweistichproben-t-Test</h3>
<blockquote>
<p>Bsp. 4 (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>): Sind die mit den Stichprobenmitteln <span class="math inline">\(\bar x_1=50.4\)</span> und <span class="math inline">\(\bar x_2=51.2\)</span> geschätzten Mittelwerte <span class="math inline">\(\mu_1\)</span> und <span class="math inline">\(\mu_2\)</span> ungleich? Beziehungsweise, können wir statistisch nachvollziehen, dass die beiden Stichproben Grundgesamtheiten mit dem selben Mittelwert entstammen?</p>
</blockquote>
</div>
<div id="ttest2gepaart" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Gepaarter Zweistichproben-t-Test</h3>
<blockquote>
<p>Bsp. 5 (Abbildung <a href="09-tests.html#fig:fmoose">9.3</a>): Ist die Anzahl Moosarten auf der Nord- und Südseite <em>derselben</em> Bäume unterschiedlich?</p>
</blockquote>
</div>
</div>
<div id="interpretation-des-p-wertes" class="section level2">
<h2><span class="header-section-number">9.3</span> Interpretation des p-Wertes</h2>
<p>An dieser Stelle ein paar Worte zur Interpretation des p-Wertes. Der p-Wert und das Signifikanzniveau (hier 0.01) hängen zusammen: Ist der p-Wert kleiner oder gleich 0.01 wird die Nullhypothese abgelehnt; ist der p-Wert groesser als 0.01 wird die Nullhypothese bis auf weiteres beibehalten. Andere Signifikanzniveaus sind üblich (0.001, 0.05 etc.) und <em>R</em> beispielsweise gibt immer mehrere an.</p>
<p>Ein p-Wert von 0.01 sagt nun aus, dass wir bei <em>hypothetisch wiederholter Stichprobenziehung</em> des selben Umfangs aus der selben Grundgesamtheit in 1% der Fälle die Nullhypothese ablehnen würden obwohl sie wahr ist - ein sogenannter <strong>Fehler 1. Art</strong>.</p>
<p>In den Worten des Wissenschaftsphilosophen Ian <span class="citation">Hacking (<a href="#ref-hacking2001" role="doc-biblioref">2001</a>)</span>: “<em>Entweder</em> ist die Nullhypothese wahr und etwas ungewöhnliches ist per Zufall geschehen (Wahrscheinlichkeit 1%), <em>oder</em> die Nullhypothese ist falsch.”</p>
</div>
<div id="fehler-1.-und-2.-art-teststaerke" class="section level2">
<h2><span class="header-section-number">9.4</span> Fehler 1. und 2. Art, Teststaerke</h2>
</div>
<div id="ftest" class="section level2">
<h2><span class="header-section-number">9.5</span> F-Test (Vergleich von Varianzen)</h2>
<blockquote>
<p>Bsp. 6 (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>): Ist die Varianz <span class="math inline">\(\sigma_2^2\)</span> (gegeben <span class="math inline">\(s_2^2=384\)</span>) groesser als die Varianz <span class="math inline">\(\sigma_1^2\)</span> (gegeben <span class="math inline">\(s_1^2=352\)</span>)? Beziehungsweise, können wir statistisch nachvollziehen, dass die beiden Stichproben Grundgesamtheiten mit derselben Varianz entstammen?</p>
</blockquote>
</div>
<div id="kstest" class="section level2">
<h2><span class="header-section-number">9.6</span> Verteilungstest (Kolmogorow-Smirnow-Test)</h2>
<blockquote>
<p>Bsp. 7 (Abbildung <a href="09-tests.html#fig:freisezeit">9.1</a>): Entstammt die Stichprobe der Reisezeit einer normalverteilten Grundgesamtheit? Die Parameter dieser Normalverteilung werden anhand der Stichprobe geschätzt.</p>
</blockquote>
<blockquote>
<p>Bsp. 8 (Abbildung <a href="09-tests.html#fig:freisezeit2">9.2</a>): Entstammen die beiden Teilstichproben der Reisezeit einer gemeinsamen Verteilung? Beziehungsweise, koennen wir das statistisch nachvollziehen?</p>
</blockquote>
</div>
<div id="chi2test" class="section level2">
<h2><span class="header-section-number">9.7</span> Unabhängigkeitstest (Chi-Quadrat-Test)</h2>
<blockquote>
<p>Bsp. 9 (Kapitel <a href="05-korrelation.html#korrelation">5</a>): Gibt es einen Zusammenhang zwischen “Bezirk” und “Votum” beim Volksentscheid Tegel? Beziehungsweise, ist der geringe Zusammenhang, den wir bereits festgestellt haben, statistisch signifikant?</p>
</blockquote>

</div>
</div>
<h3>Literatur</h3>
<div id="refs" class="references">
<div id="ref-dormann2013">
<p>Dormann, C. F. 2013. <em>Parametrische Statistik</em>. Berlin: Springer.</p>
</div>
<div id="ref-hacking2001">
<p>Hacking, I. 2001. <em>An Introduction to Probability and Inductive Logic</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-mittag2016">
<p>Mittag, H. J. 2016. <em>Statistik (4. Auflage)</em>. Berlin: Springer Spektrum.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Die Erhebung der Anreisezeiten war im digitalen Wintersemester 2020/21 leider nicht moeglich, weshalb wir hier auf die Daten vom letzten Jahr zurueckgreifen.<a href="09-tests.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Die Fragestellungen sind etwas konstruiert, damit wir die gaengigsten Versionen des t-Tests kennenlernen, sind aber halbwegs realistisch.<a href="09-tests.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>In der Tat hat der t-Test seinen Namen von der t-Verteilung seiner Teststatistik.<a href="09-tests.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="08-schaetzen.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="10-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
